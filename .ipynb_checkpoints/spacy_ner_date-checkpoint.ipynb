{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ola 0 Xxx ADJ|M|S|@>N\n",
      "mundo 4 xxxx <np-idf>|N|M|S|@<ACC\n",
      ", 9 , PU|@PU\n",
      "tudo 11 xxxx <quant>|ADV|@>A\n",
      "bem 16 xxx <quant>|ADV|@>A\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('pt')\n",
    "sample = nlp('Ola mundo, tudo bem')\n",
    "for t in sample:\n",
    "    print (t, t.idx, t.shape_, t.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "TRAIN_DATA = [\n",
    "    (u\"Bom dia Eliezer\", {\"entities\": [(8, 15, \"PERSON\")]}),\n",
    "    (u\"Cookie fica feliz quando o dono chega em casa\", {'entities': [(0, 6, 'ANIMAL')]}),\n",
    "    (u\"Cookie e o melhor amigo do homem\", {'entities': [(0, 6, 'ANIMAL')]}),\n",
    "    (u\"cookie soltam pelos e são independentes\", {'entities': [(0, 6, 'ANIMAL')]}),\n",
    "    (u\"I like London and Berlin.\", {\"entities\": [(7, 13, \"LOC\"), (18, 24, \"LOC\")]}),\n",
    "    (u'Acender as luzes do Jardim', {'entities': [(20, 26, 'LOC')] }),\n",
    "    (u'Almira é uma ótima pessoa, gosto muito dela', { 'entities': [(0, 6, 'PERSON')] }),\n",
    "    (u'Acender as luzes do jardim suspenso', {'entities': [(20, 25, 'LOC')] }),\n",
    "    (u'João foi para Bahia nas férias', { 'entities': [ (0, 4, 'PERSON') , (14, 19, 'LOC') ] }),\n",
    "    (u'eliezer foi visitar João na casa de praia', {  'entities': [(0, 7, 'PERSON') , (28, 41, 'LOC') ] }),\n",
    "    (u'Eliezer e Juliana foram jantar no Jardins', { 'entities': [(0, 7, 'PERSON') , (10, 17, 'PERSON') , (34, 41, 'LOC') ] }),\n",
    "    (u'No meio do ano irei para São Paulo fazer mais um curso', { 'entities': [(25, 34, 'LOC')] }),\n",
    "    (u'O sonho dela era ir para Autrália visitar seu irmão', { 'entities': [(25, 33, 'LOC')] }),\n",
    "    (u'Em 15/07/1988 nasceu uma lista criança', { 'entities': [(3, 13, 'DATE')] }),\n",
    "    (u'Data de Prisão: 10/01/2018', { 'entities': [(16, 26, 'DATE')] }),\n",
    "    (u'No dia 01/02/2016 foi decretado a sentença', { 'entities': [(7, 17, 'DATE')] }),\n",
    "    (u'A data da festa foi 07/05/2018', {'entities': [(20, 30, 'DATE')] }),\n",
    "    (u'Eliezer é médico', {'entities': [(0, 7, 'PERSON')] }),\n",
    "    (u'Os médicos são pessoas importantes e muitos moram em São Paulo', { 'entities': [(53, 62, 'LOC')] }),\n",
    "    (u'Sofia é inteligente', {'entities': [(0, 5, 'PERSON')] }),\n",
    "    (u'Bom dia Sofia', {'entities': [(8, 13, 'PERSON')] }),\n",
    "    (u'Sofia reguar as plantas', {'entities': [(0, 5, 'PERSON'), (16, 23, 'LOC')] })    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = [('Que dia e hoje\\r', {'entities': [(10, 14, 'DATA')]}), ('Foi ontem a tarde\\r', {'entities': [(4, 10, 'PASSADO')]}), ('Amanha vai chover\\r', {'entities': [(0, 7, 'FUTURO'), (7, 11, 'FUTURO')]}), ('Qual as vendas de semana passada\\r', {'entities': [(25, 32, 'PASSADO'), (18, 25, 'DATA')]}), ('Qual o resultado do Q1\\r', {'entities': [(20, 22, 'DATA')]}), ('Qual o resultado do Q2\\r', {'entities': [(20, 22, 'DATA')]}), ('Qual o resultado do Q3\\r', {'entities': [(20, 22, 'DATA')]}), ('O melhor quarter foi o Q4\\r', {'entities': [(9, 17, 'DATA'), (23, 25, 'DATA')]}), ('As vendas do trimestre foram otimas\\r', {'entities': [(13, 23, 'DATA'), (23, 29, 'PASSADO')]}), ('O resultado do semestre foi regular\\r', {'entities': [(15, 24, 'DATA'), (24, 28, 'PASSADO')]}), ('A nossa previsao e para o segundo semestre\\r', {'entities': [(8, 17, 'FUTURO'), (34, 42, 'DATA')]}), ('O resultado no ano passado\\r', {'entities': [(19, 26, 'PASSADO'), (15, 19, 'DATA')]}), ('Voce tem o relatario do ultimo trimestre\\r', {'entities': [(24, 31, 'PASSADO'), (31, 40, 'DATA')]}), ('Hoje e 23/Jan\\r', {'entities': [(0, 5, 'PRESENTE'), (7, 13, 'DATA')]}), ('Ontem foi segunda 24 de marco\\r', {'entities': [(0, 6, 'PASSADO'), (6, 10, 'PASSADO'), (18, 29, 'DATA'), (10, 18, 'DATA')]}), ('A data correta e 10/Dez/19\\r', {'entities': [(17, 26, 'DATA')]}), ('A reuniao e na proxima sexta feira\\r', {'entities': [(15, 23, 'FUTURO'), (23, 34, 'DATA')]}), ('A data foi remarcada para a proxima quarta\\r', {'entities': [(7, 11, 'PASSADO'), (28, 35, 'FUTURO'), (36, 42, 'DATA')]}), ('Eu nasci em 24/10/1983\\r', {'entities': [(12, 22, 'DATA')]}), ('A segunda guerra terminou em 45\\r', {'entities': [(17, 26, 'PASSADO'), (29, 31, 'DATA')]}), ('na sexta ele faltou\\r', {'entities': [(3, 9, 'DATA'), (13, 19, 'PASSADO')]}), ('Meu pai nasce nos anos 60\\r', {'entities': [(18, 25, 'DATA')]}), ('ninguem trabalha aos domingos\\r', {'entities': [(21, 29, 'DATA')]}), ('sabado e o melhor dia de vendas\\r', {'entities': [(0, 7, 'DATA')]}), ('As anos 80 foi trash\\r', {'entities': [(3, 10, 'DATA')]}), ('Eu em casei da decada de 90\\r', {'entities': [(15, 27, 'DATA')]}), ('A decada de 2000 teve o bug do milenio\\r', {'entities': [(2, 16, 'DATA')]}), ('As vendas totais de julho\\r', {'entities': [(20, 25, 'DATA')]}), ('As vendas totais de agosto\\r', {'entities': [(20, 26, 'DATA')]}), ('As vendas totais de setembro\\r', {'entities': [(20, 28, 'DATA')]}), ('As vendas totais de novembro\\r', {'entities': [(20, 28, 'DATA')]}), ('As vendas totais de dezembro\\r', {'entities': [(20, 28, 'DATA')]}), ('toda as quinta temos reuniao\\r', {'entities': [(8, 15, 'DATA')]}), ('As vendas totais de outubro\\r', {'entities': [(20, 27, 'DATA')]}), ('Me manda o email de 2 dias atras\\r', {'entities': [(20, 26, 'DATA'), (27, 32, 'PASSADO')]}), ('Me manda o email de 5 dias atras\\r', {'entities': [(20, 26, 'DATA'), (27, 32, 'PASSADO')]}), ('Me manda o email de 7 dias atras\\r', {'entities': [(20, 25, 'DATA'), (27, 32, 'PASSADO')]}), ('Daqui ha 2 semanas\\r', {'entities': [(0, 8, 'PASSADO'), (9, 18, 'DATA')]}), ('quinta feira passada nao foi bom\\r', {'entities': [(0, 12, 'DATA'), (13, 21, 'PASSADO'), (25, 29, 'PASSADO')]}), ('Isso antes de ontem\\r', {'entities': [(5, 19, 'PASSADO')]}), ('Aconteceu ha 15 dias atras\\r', {'entities': [(0, 10, 'PASSADO'), (10, 13, 'PASSADO'), (13, 21, 'DATA'), (21, 26, 'PASSADO')]}), ('No calendario estava como 12 de janeiro\\r', {'entities': [(14, 21, 'PASSADO'), (26, 39, 'DATA')]}), ('A minha agenda esta livre o na terca\\r', {'entities': [(31, 36, 'DATA')]}), ('Vou viajar na proxima sexta-feira\\r', {'entities': [(14, 22, 'FUTURO'), (22, 33, 'DATA')]}), ('resultado da loja em janeiro\\r', {'entities': [(21, 28, 'DATA')]}), ('resultado da loja em fevereiro\\r', {'entities': [(21, 30, 'DATA')]}), ('resultado da loja em marco\\r', {'entities': [(21, 26, 'DATA')]}), ('resultado da loja em abril\\r', {'entities': [(21, 26, 'DATA')]}), ('resultado da loja em maio\\r', {'entities': [(21, 25, 'DATA')]}), ('resultado da loja em junho\\r', {'entities': [(21, 26, 'DATA')]}), ('resultado da loja em julho\\r', {'entities': [(21, 26, 'DATA')]}), ('resultado do vendendor em janeiro de 2019\\r', {'entities': [(26, 41, 'DATA')]}), ('resultado do vendendor em ano passado\\r', {'entities': [(26, 30, 'DATA'), (30, 37, 'PASSADO')]}), ('resultado do vendendor em mes passado\\r', {'entities': [(26, 37, 'PASSADO')]}), ('resultado do vendendor em semana passado\\r', {'entities': [(33, 40, 'PASSADO'), (26, 33, 'DATA')]}), ('resultado do vendendor em ontem\\r', {'entities': [(26, 31, 'PASSADO')]}), ('Forecast de novembro\\r', {'entities': [(0, 8, 'FUTURO'), (12, 20, 'DATA')]}), ('Forecast de proximo mes\\r', {'entities': [(0, 9, 'FUTURO'), (12, 20, 'FUTURO'), (20, 23, 'DATA')]}), ('Forecast de daqui um mes\\r', {'entities': [(0, 9, 'FUTURO'), (21, 24, 'DATA'), (12, 17, 'FUTURO')]}), ('Forecast de daqui dois mes\\r', {'entities': [(0, 9, 'DATA'), (12, 18, 'FUTURO'), (23, 26, 'DATA')]}), ('Como sera as vendas nos proximos 3 meses\\r', {'entities': [(35, 40, 'DATA'), (24, 32, 'FUTURO'), (0, 9, 'FUTURO')]}), ('Na quarta dia 04/03 ele estara aqui\\r', {'entities': [(14, 19, 'DATA'), (3, 10, 'DATA'), (24, 31, 'FUTURO')]}), ('Previsao de vendas para dez/2020\\r', {'entities': [(0, 9, 'FUTURO'), (24, 32, 'DATA')]}), ('Previsao de vendas para ago/2021\\r', {'entities': [(0, 9, 'FUTURO'), (25, 32, 'DATA')]}), ('Previsao de vendas para jan/2021\\r', {'entities': [(0, 9, 'FUTURO'), (24, 32, 'DATA')]}), ('A data de hoje e 12/12/20\\r', {'entities': [(17, 25, 'DATA'), (10, 15, 'PRESENTE')]}), ('A loja da rua aratas fechou em 01/03/2019\\r', {'entities': [(21, 27, 'PASSADO'), (31, 41, 'DATA')]})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'pt' model\n"
     ]
    }
   ],
   "source": [
    "model= None\n",
    "output_dir=\"C:/Users/eliez/AnacondaProjects/Spacy_date/model\" \n",
    "n_iter=5\n",
    "\n",
    "\"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "if model != None:\n",
    "    nlp = spacy.load(output_dir)  # load existing spaCy model\n",
    "    print(\"Loaded model '%s'\" % output_dir)\n",
    "else:\n",
    "    nlp = spacy.blank(\"pt\")  # create blank Language class\n",
    "    print(\"Created blank 'pt' model\")\n",
    "    \n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe(\"ner\")\n",
    "    nlp.add_pipe(ner, last=True)\n",
    "# otherwise, get it so we can add labels\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# add labels\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "# get names of other pipes to disable them during training\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E109] Model for component 'ner' not initialized. Did you forget to load a model, or forget to call begin_training()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-216-f479478ad7cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m                     \u001b[0mannotations\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# batch of annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# dropout - make it harder to memorise data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                     losses=losses )\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Losses\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Eliezer\\python\\env\\dpnlp\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, docs, golds, drop, sgd, losses, component_cfg)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomponent_cfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"drop\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m             \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m                 \u001b[0msgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.update\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.require_model\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E109] Model for component 'ner' not initialized. Did you forget to load a model, or forget to call begin_training()?"
     ]
    }
   ],
   "source": [
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    # reset and initialize the weights randomly – but only if we're\n",
    "    # training a new model\n",
    "    if model =='':\n",
    "        nlp.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            #print(texts)\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    drop=0.5,  # dropout - make it harder to memorise data\n",
    "                    losses=losses )\n",
    "        print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('quarta', 'DATA')] A DATA foi remarcada para a proxima quarta\n",
      "Entities [('12 de janeiro', 'DATA')] No calendario estava como 12 de janeiro\n",
      "Entities [('Hoje', 'AGORA'), ('23/Jan', 'DATA')] Hoje e 23/Jan\n",
      "Entities [('15 dias', 'DATA'), ('atras', 'PASSADO')] Aconteceu ha 15 dias atras\n",
      "Entities [('terca', 'DATA')] A minha agenda esta livre o na terca\n",
      "Entities [('24/10/1983', 'DATA')] Eu nasci em 24/10/1983\n",
      "Entities [('anos 80', 'DATA')] As anos 80 foi trash\n",
      "Entities [('24 de marco', 'DATA')] Ontem foi segunda 24 de marco\n",
      "Entities [] Qual as vendas de semana passada\n",
      "Entities [('anos 60', 'DATA')] Meu pai nasce nos anos 60\n",
      "Entities [('7 dias', 'DATA'), ('atras', 'PASSADO')] Me manda o email de 7 dias atras\n",
      "Entities [('sexta-feira', 'DATA')] A reuniao e na proxima sexta-feira\n",
      "Entities [('5 dias', 'DATA'), ('atras', 'PASSADO')] Me manda o email de 5 dias atras\n",
      "Entities [('2 dias', 'DATA'), ('atras', 'PASSADO')] Me manda o email de 2 dias atras\n",
      "Entities [('Daqui ha', 'FUTURO'), ('2 semanas', 'DATA')] Daqui ha 2 semanas\n",
      "Entities [('hoje', 'DATA')] Que dia e hoje\n",
      "Entities [('antes de', 'PASSADO')] Isso antes de ontem\n",
      "Entities [('PASSADO', 'DATA')] O resultado no ano PASSADO\n",
      "Entities [] Foi ontem a tarde\n",
      "Entities [('trimestre', 'DATA')] Voce tem o relatario do ultimo trimestre\n",
      "Entities [] Amanha vai chover\n",
      "Entities [('45', 'DATA')] A segunda guerra terminou em 45\n"
     ]
    }
   ],
   "source": [
    "# test the trained model\n",
    "for text, _ in TRAIN_DATA:\n",
    "    doc = nlp(text)\n",
    "    print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents] , text )\n",
    "    #print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to C:\\Users\\eliez\\AnacondaProjects\\Spacy_date\\model\n"
     ]
    }
   ],
   "source": [
    "# save model to output directory\n",
    "if output_dir !='':\n",
    "    output_dir = Path(output_dir)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "    nlp.to_disk(output_dir)\n",
    "    print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from C:\\Users\\eliez\\AnacondaProjects\\Spacy_date\\model\n",
      "Entities [('atras', 'PASSADO')]\n",
      "Tokens [('Me', '', 2), ('manda', '', 2), ('o', '', 2), ('email', '', 2), ('de', '', 2), ('7', '', 2), ('dias', '', 2), ('atras', 'PASSADO', 3), ('\\r', '', 2)]\n",
      "Entities [('dezembro', 'DATA')]\n",
      "Tokens [('As', '', 2), ('vendas', '', 2), ('totais', '', 2), ('de', '', 2), ('dezembro', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('abril', 'DATA')]\n",
      "Tokens [('resultado', '', 2), ('da', '', 2), ('loja', '', 2), ('em', '', 2), ('abril', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('12 de janeiro', 'DATA')]\n",
      "Tokens [('No', '', 2), ('calendario', '', 2), ('estava', '', 2), ('como', '', 2), ('12', 'DATA', 3), ('de', 'DATA', 1), ('janeiro', 'DATA', 1), ('\\r', '', 2)]\n",
      "Entities [('Forecast', 'FUTURO'), ('daqui', 'FUTURO'), ('mes', 'DATA')]\n",
      "Tokens [('Forecast', 'FUTURO', 3), ('de', '', 2), ('d', 'FUTURO', 3), ('aqui', 'FUTURO', 1), ('um', '', 2), ('mes', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('anos 80', 'DATA')]\n",
      "Tokens [('As', '', 2), ('anos', 'DATA', 3), ('80', 'DATA', 1), ('foi', '', 2), ('trash', '', 2), ('\\r', '', 2)]\n",
      "Entities [('10/Dez/19', 'DATA')]\n",
      "Tokens [('A', '', 2), ('data', '', 2), ('correta', '', 2), ('e', '', 2), ('10/Dez/19', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('janeiro', 'DATA')]\n",
      "Tokens [('resultado', '', 2), ('da', '', 2), ('loja', '', 2), ('em', '', 2), ('janeiro', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('maio', 'DATA')]\n",
      "Tokens [('resultado', '', 2), ('da', '', 2), ('loja', '', 2), ('em', '', 2), ('maio', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('anos 60', 'DATA')]\n",
      "Tokens [('Meu', '', 2), ('pai', '', 2), ('nasce', '', 2), ('nos', '', 2), ('anos', 'DATA', 3), ('60', 'DATA', 1), ('\\r', '', 2)]\n",
      "Entities []\n",
      "Tokens [('Foi', '', 2), ('ontem', '', 2), ('a', '', 2), ('tarde', '', 2), ('\\r', '', 2)]\n",
      "Entities [('passado', 'PASSADO')]\n",
      "Tokens [('resultado', '', 2), ('do', '', 2), ('vendendor', '', 2), ('em', '', 2), ('ano', '', 2), ('passado', 'PASSADO', 3), ('\\r', '', 2)]\n",
      "Entities [('julho', 'DATA')]\n",
      "Tokens [('As', '', 2), ('vendas', '', 2), ('totais', '', 2), ('de', '', 2), ('julho', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('setembro', 'DATA')]\n",
      "Tokens [('As', '', 2), ('vendas', '', 2), ('totais', '', 2), ('de', '', 2), ('setembro', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities []\n",
      "Tokens [('resultado', '', 2), ('do', '', 2), ('vendendor', '', 2), ('em', '', 2), ('ontem', '', 2), ('\\r', '', 2)]\n",
      "Entities [('2 dias', 'DATA'), ('atras', 'PASSADO')]\n",
      "Tokens [('Me', '', 2), ('manda', '', 2), ('o', '', 2), ('email', '', 2), ('de', '', 2), ('2', 'DATA', 3), ('dias', 'DATA', 1), ('atras', 'PASSADO', 3), ('\\r', '', 2)]\n",
      "Entities [('faltou', 'PASSADO')]\n",
      "Tokens [('na', '', 2), ('sexta', '', 2), ('ele', '', 2), ('faltou', 'PASSADO', 3), ('\\r', '', 2)]\n",
      "Entities [('antes de ontem', 'PASSADO')]\n",
      "Tokens [('Isso', '', 2), ('antes', 'PASSADO', 3), ('de', 'PASSADO', 1), ('ontem', 'PASSADO', 1), ('\\r', '', 2)]\n",
      "Entities [('sexta-feira', 'DATA')]\n",
      "Tokens [('Vou', '', 2), ('viajar', '', 2), ('na', '', 2), ('proxima', '', 2), ('sexta-feira', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('Forecast', 'FUTURO'), ('novembro', 'DATA')]\n",
      "Tokens [('Forecast', 'FUTURO', 3), ('de', '', 2), ('novembro', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('24/10/1983', 'DATA')]\n",
      "Tokens [('Eu', '', 2), ('nasci', '', 2), ('em', '', 2), ('24/10/1983', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('outubro', 'DATA')]\n",
      "Tokens [('As', '', 2), ('vendas', '', 2), ('totais', '', 2), ('de', '', 2), ('outubro', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('junho', 'DATA')]\n",
      "Tokens [('resultado', '', 2), ('da', '', 2), ('loja', '', 2), ('em', '', 2), ('junho', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('trimestre', 'DATA')]\n",
      "Tokens [('Voce', '', 2), ('tem', '', 2), ('o', '', 2), ('relatario', '', 2), ('do', '', 2), ('ultimo', '', 2), ('trimestre', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('passada', 'PASSADO')]\n",
      "Tokens [('Qual', '', 2), ('as', '', 2), ('vendas', '', 2), ('de', '', 2), ('semana', '', 2), ('passada', 'PASSADO', 3), ('\\r', '', 2)]\n",
      "Entities [('semestre', 'DATA')]\n",
      "Tokens [('A', '', 2), ('nossa', '', 2), ('previsao', '', 2), ('e', '', 2), ('para', '', 2), ('o', '', 2), ('segundo', '', 2), ('semestre', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('15 dias', 'DATA'), ('atras', 'PASSADO')]\n",
      "Tokens [('Aconteceu', '', 2), ('ha', '', 2), ('15', 'DATA', 3), ('dias', 'DATA', 1), ('atras', 'PASSADO', 3), ('\\r', '', 2)]\n",
      "Entities [('decada de 2000', 'DATA')]\n",
      "Tokens [('A', '', 2), ('decada', 'DATA', 3), ('de', 'DATA', 1), ('2000', 'DATA', 1), ('teve', '', 2), ('o', '', 2), ('bug', '', 2), ('do', '', 2), ('milenio', '', 2), ('\\r', '', 2)]\n",
      "Entities [('5 dias', 'DATA'), ('atras', 'PASSADO')]\n",
      "Tokens [('Me', '', 2), ('manda', '', 2), ('o', '', 2), ('email', '', 2), ('de', '', 2), ('5', 'DATA', 3), ('dias', 'DATA', 1), ('atras', 'PASSADO', 3), ('\\r', '', 2)]\n",
      "Entities [('Forecast', 'FUTURO'), ('mes', 'DATA')]\n",
      "Tokens [('Forecast', 'FUTURO', 3), ('de', '', 2), ('proximo', '', 2), ('mes', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('sexta feira', 'DATA')]\n",
      "Tokens [('A', '', 2), ('reuniao', '', 2), ('e', '', 2), ('na', '', 2), ('proxima', '', 2), ('sexta', 'DATA', 3), ('feira', 'DATA', 1), ('\\r', '', 2)]\n",
      "Entities [('quinta temos', 'DATA')]\n",
      "Tokens [('toda', '', 2), ('as', '', 2), ('quinta', 'DATA', 3), ('temos', 'DATA', 1), ('reuniao', '', 2), ('\\r', '', 2)]\n",
      "Entities [('Como sera', 'FUTURO'), ('proximos', 'FUTURO'), ('meses', 'DATA')]\n",
      "Tokens [('Como', 'FUTURO', 3), ('sera', 'FUTURO', 1), ('as', '', 2), ('vendas', '', 2), ('nos', '', 2), ('proximos', 'FUTURO', 3), ('3', '', 2), ('meses', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('Q1', 'DATA')]\n",
      "Tokens [('Qual', '', 2), ('o', '', 2), ('resultado', '', 2), ('do', '', 2), ('Q1', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('Hoje e', 'FUTURO'), ('23/Jan', 'DATA')]\n",
      "Tokens [('Hoje', 'FUTURO', 3), ('e', 'FUTURO', 1), ('23/Jan', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities []\n",
      "Tokens [('O', '', 2), ('resultado', '', 2), ('do', '', 2), ('semestre', '', 2), ('foi', '', 2), ('regular', '', 2), ('\\r', '', 2)]\n",
      "Entities [('decada de 90', 'DATA')]\n",
      "Tokens [('Eu', '', 2), ('em', '', 2), ('casei', '', 2), ('da', '', 2), ('decada', 'DATA', 3), ('de', 'DATA', 1), ('90', 'DATA', 1), ('\\r', '', 2)]\n",
      "Entities [('Q3', 'DATA')]\n",
      "Tokens [('Qual', '', 2), ('o', '', 2), ('resultado', '', 2), ('do', '', 2), ('Q3', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('quarta', 'DATA')]\n",
      "Tokens [('A', '', 2), ('data', '', 2), ('foi', '', 2), ('remarcada', '', 2), ('para', '', 2), ('a', '', 2), ('proxima', '', 2), ('quarta', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('Previsao', 'FUTURO'), ('jan/2021', 'DATA')]\n",
      "Tokens [('Previsao', 'FUTURO', 3), ('de', '', 2), ('vendas', '', 2), ('para', '', 2), ('jan/2021', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('passado', 'PASSADO')]\n",
      "Tokens [('resultado', '', 2), ('do', '', 2), ('vendendor', '', 2), ('em', '', 2), ('semana', '', 2), ('passado', 'PASSADO', 3), ('\\r', '', 2)]\n",
      "Entities [('Previsao', 'FUTURO'), ('ago/2021', 'DATA')]\n",
      "Tokens [('Previsao', 'FUTURO', 3), ('de', '', 2), ('vendas', '', 2), ('para', '', 2), ('ago/2021', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('mes passado', 'PASSADO')]\n",
      "Tokens [('resultado', '', 2), ('do', '', 2), ('vendendor', '', 2), ('em', '', 2), ('mes', 'PASSADO', 3), ('passado', 'PASSADO', 1), ('\\r', '', 2)]\n",
      "Entities []\n",
      "Tokens [('As', '', 2), ('vendas', '', 2), ('do', '', 2), ('trimestre', '', 2), ('foram', '', 2), ('otimas', '', 2), ('\\r', '', 2)]\n",
      "Entities [('fechou', 'PASSADO'), ('01/03/2019', 'DATA')]\n",
      "Tokens [('A', '', 2), ('loja', '', 2), ('da', '', 2), ('rua', '', 2), ('aratas', '', 2), ('fechou', 'PASSADO', 3), ('em', '', 2), ('01/03/2019', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('04/03', 'DATA')]\n",
      "Tokens [('Na', '', 2), ('quarta', '', 2), ('dia', '', 2), ('04/03', 'DATA', 3), ('ele', '', 2), ('estara', '', 2), ('aqui', '', 2), ('\\r', '', 2)]\n",
      "Entities [('agosto', 'DATA')]\n",
      "Tokens [('As', '', 2), ('vendas', '', 2), ('totais', '', 2), ('de', '', 2), ('agosto', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('45', 'DATA')]\n",
      "Tokens [('A', '', 2), ('segunda', '', 2), ('guerra', '', 2), ('terminou', '', 2), ('em', '', 2), ('45', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('Previsao', 'FUTURO'), ('dez/2020', 'DATA')]\n",
      "Tokens [('Previsao', 'FUTURO', 3), ('de', '', 2), ('vendas', '', 2), ('para', '', 2), ('dez/2020', 'DATA', 3), ('\\r', '', 2)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('fevereiro', 'DATA')]\n",
      "Tokens [('resultado', '', 2), ('da', '', 2), ('loja', '', 2), ('em', '', 2), ('fevereiro', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('Q2', 'DATA')]\n",
      "Tokens [('Qual', '', 2), ('o', '', 2), ('resultado', '', 2), ('do', '', 2), ('Q2', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('hoje', 'DATA')]\n",
      "Tokens [('Que', '', 2), ('dia', '', 2), ('e', '', 2), ('hoje', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('24 de marco', 'DATA')]\n",
      "Tokens [('Ontem', '', 2), ('foi', '', 2), ('segunda', '', 2), ('24', 'DATA', 3), ('de', 'DATA', 1), ('marco', 'DATA', 1), ('\\r', '', 2)]\n",
      "Entities [('domingos', 'DATA')]\n",
      "Tokens [('ninguem', '', 2), ('trabalha', '', 2), ('a', '', 2), ('os', '', 2), ('domingos', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('Q4', 'DATA')]\n",
      "Tokens [('O', '', 2), ('melhor', '', 2), ('quarter', '', 2), ('foi', '', 2), ('o', '', 2), ('Q4', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities []\n",
      "Tokens [('O', '', 2), ('resultado', '', 2), ('no', '', 2), ('ano', '', 2), ('passado', '', 2), ('\\r', '', 2)]\n",
      "Entities [('quinta feira', 'DATA')]\n",
      "Tokens [('quinta', 'DATA', 3), ('feira', 'DATA', 1), ('passada', '', 2), ('nao', '', 2), ('foi', '', 2), ('bom', '', 2), ('\\r', '', 2)]\n",
      "Entities [('terca', 'DATA')]\n",
      "Tokens [('A', '', 2), ('minha', '', 2), ('agenda', '', 2), ('esta', '', 2), ('livre', '', 2), ('o', '', 2), ('na', '', 2), ('terca', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('Forecast', 'FUTURO'), ('daqui', 'FUTURO'), ('mes', 'DATA')]\n",
      "Tokens [('Forecast', 'FUTURO', 3), ('de', '', 2), ('d', 'FUTURO', 3), ('aqui', 'FUTURO', 1), ('dois', '', 2), ('mes', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities []\n",
      "Tokens [('sabado', '', 2), ('e', '', 2), ('o', '', 2), ('melhor', '', 2), ('dia', '', 2), ('de', '', 2), ('vendas', '', 2), ('\\r', '', 2)]\n",
      "Entities [('janeiro de 2019', 'DATA')]\n",
      "Tokens [('resultado', '', 2), ('do', '', 2), ('vendendor', '', 2), ('em', '', 2), ('janeiro', 'DATA', 3), ('de', 'DATA', 1), ('2019', 'DATA', 1), ('\\r', '', 2)]\n",
      "Entities [('Daqui ha', 'PASSADO'), ('2 semanas', 'DATA')]\n",
      "Tokens [('Daqui', 'PASSADO', 3), ('ha', 'PASSADO', 1), ('2', 'DATA', 3), ('semanas', 'DATA', 1), ('\\r', '', 2)]\n",
      "Entities [('marco', 'DATA')]\n",
      "Tokens [('resultado', '', 2), ('da', '', 2), ('loja', '', 2), ('em', '', 2), ('marco', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('julho', 'DATA')]\n",
      "Tokens [('resultado', '', 2), ('da', '', 2), ('loja', '', 2), ('em', '', 2), ('julho', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('novembro', 'DATA')]\n",
      "Tokens [('As', '', 2), ('vendas', '', 2), ('totais', '', 2), ('de', '', 2), ('novembro', 'DATA', 3), ('\\r', '', 2)]\n",
      "Entities [('Amanha vai', 'FUTURO')]\n",
      "Tokens [('Amanha', 'FUTURO', 3), ('vai', 'FUTURO', 1), ('chover', '', 2), ('\\r', '', 2)]\n",
      "Entities [('12/12/20', 'DATA')]\n",
      "Tokens [('A', '', 2), ('data', '', 2), ('de', '', 2), ('hoje', '', 2), ('e', '', 2), ('12/12/20', 'DATA', 3), ('\\r', '', 2)]\n"
     ]
    }
   ],
   "source": [
    "# test the saved model\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp2 = spacy.load(output_dir)\n",
    "for text, _ in TRAIN_DATA:\n",
    "    doc = nlp2(text)\n",
    "    print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Forecast', 'FUTURO'), ('Q4', 'DATA')]\n",
      "Tokens [('Forecast', 'FUTURO', 3), ('do', '', 2), ('Q4', 'DATA', 3)]\n"
     ]
    }
   ],
   "source": [
    "text = 'Forecast do Q4'\n",
    "doc = nlp2(text)\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
